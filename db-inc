# $Id: db-inc,v 1.5 2006/05/05 01:38:33 judd Exp $

[ "$UID" = "" ] && UID=`uid`
TMPDIR="/tmp/archpkg.$arch.$repoid.$UID"

# where are the arch scripts located?
ARCHDIR="/arch"

if [ ! `type -p fakeroot` ]; then
	echo "error: fakeroot is missing" >&2
	exit 1
fi

if [ ! -d $stagedir ]; then
	echo "error: staging directory missing: $stagedir" >&2
	exit 1
fi

cleanup() {
	rm -rf $TMPDIR
	# unlock
	rm -f /tmp/.repolck.$arch.$repoid
	[ "$1" ] && exit $1
}

ctrl_c() {
	echo "Interrupted" >&2
	cleanup 0
}

die() {
	echo "$*" >&2
	cleanup 1
}

# check for locks
if [ -f /tmp/.repolck.$arch.$repoid ]; then
	owner=`/bin/ls -l /tmp/.repolck.$arch.$repoid | awk '{print $3}'`
	echo "error: db generation is already in progress (started by $owner)"
	exit 1
fi

# catch ^C breaks
trap ctrl_c SIGINT
# lock
touch /tmp/.repolck.$arch.$repoid

# RedHat's mktemp is broken...
if [ -d $TMPDIR ]; then
	echo "==> Removing old temp dir..." >&2
	rm -rf $TMPDIR || exit 1
fi
mkdir $TMPDIR; [ $? -gt 0 ] && exit 1

cd $TMPDIR

# Checkout the CVS module if we need to
updatelists=
if [ "`ls $stagedir/add`" -o "`ls $stagedir/del`" ]; then
	# if $cvsdir is set, then use that instead of doing our own cvs checkout
	if [ "$cvsdir" ]; then
		mv $cvsdir $TMPDIR/$cvsmod
	else
		echo "==> Checking out module: $cvsmod ($cvstag)"
		CVS_RSH=ssh CVSROOT=:ext:cvs.archlinux.org:$cvspath cvs -q export -r $cvstag $cvsmod
		if [ $? -gt 0 ]; then
			die "==> CVS export failed!"
		fi
	fi
	updatelists=1
else
	echo "No files to process"
	cleanup 0
fi

# Right-O, now we look through the "add" and "del" subdirectories of
# $stagedir and process the packages there accordingly -- all packages
# in the "add" dir are added/updated, all packages in the "del" dir
# are removed.
#
# This means the sync db could actually be unpacked/repacked twice in
# one db-* invocation, but it's not a huge performance hit.

if [ -d $stagedir/add -a "`ls $stagedir/add`" ]; then
	cd $TMPDIR
	echo "==> Processing new/updated packages for repository '$reponame'..." >&2

	# copy the db file into our working area
	cp $ftppath/$reponame.db.tar.gz .

	cd $stagedir/add
	# run it thru fakeroot make sure everything is owned by root.root
	echo "$ARCHDIR/updatesync-many add $TMPDIR/$reponame.db.tar.gz $TMPDIR/$cvsmod" \
		| fakeroot

	if [ $? -ne 0 ]; then
		die "==> Error returned from updatesync-many"
	fi

	cp $TMPDIR/$reponame.db.tar.gz $ftppath

	# only for i686 (for now)
	if [ "$arch" = "i686" ]; then
		echo "==> Scanning for New/Updated packages..." >&2
		cd $stagedir/add
		$ARCHDIR/pkgdb1 $TMPDIR/$cvsmod | $ARCHDIR/pkgdb2-add $repoid $stagedir/add
	fi

	# move the package files into the ftp directory
	mv -f $stagedir/add/*.pkg.tar.gz $ftppath
fi
	
if [ -d $stagedir/del -a "`ls $stagedir/del`" ]; then
	cd $TMPDIR
	echo "==> Processing deleted packages for repository '$reponame'..." >&2

	# copy the db file into our working area
	cp $ftppath/$reponame.db.tar.gz .

	cd $stagedir/del
	# run it thru fakeroot make sure everything is owned by root.root
	echo "$ARCHDIR/updatesync-many del $TMPDIR/$reponame.db.tar.gz NOT-USED" \
		| fakeroot

	if [ $? -ne 0 ]; then
		die "==> Error returned from updatesync-many"
	fi

	cp $TMPDIR/$reponame.db.tar.gz $ftppath

	# only for i686 (for now)
	if [ "$arch" = "i686" ]; then
		echo "==> Scanning for Deleted packages..." >&2
		cd $stagedir/del
		(
			for i in *.pkg.tar.gz; do
				pkgname=${i%-*-*}
				echo $pkgname
			done
		) | $ARCHDIR/pkgdb2-del $repoid $stagedir/del
	fi

  # remove the package files
	rm -f $stagedir/del/*.pkg.tar.gz
fi

if [ "$updatelists" ]; then
	echo "==> Generating Text Package List..." >&2
	cd $TMPDIR/$cvsmod
	$ARCHDIR/genpkglist $ftppath

	# hack -- only Current's packages.txt goes in a "setup" subdir
	if [ "$reponame" = "current" ]; then
		mv packages.txt $ftppath/setup/packages.txt
	else
		mv packages.txt $ftppath/packages.txt
	fi
fi

cleanup

# vim: set ts=2 noet ft=sh:
